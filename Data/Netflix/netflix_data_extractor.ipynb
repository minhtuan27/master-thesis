{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Prize Dataset\n",
    "## Extract a small sub-dataset\n",
    "Here, we choose the top 1000 most rated movies. Then, among those movies, we choose the top 1000 users who rated the most number of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'Raw/training_set'\n",
    "file_lengths = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # Get the length of the file\n",
    "    file_length = os.path.getsize(filepath)\n",
    "    \n",
    "    # Append the filename and length to the list\n",
    "    file_lengths.append((filename, file_length))\n",
    "\n",
    "# Sort the file_lengths list based on the file length in descending order\n",
    "file_lengths.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 1000 longest files\n",
    "top_1000_longest_files = file_lengths[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie and user mappings\n",
    "movie_mapping = {}\n",
    "user_mapping = {}\n",
    "\n",
    "# User rating counters\n",
    "user_ratings = {}\n",
    "\n",
    "def count_user_ratings(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Save the first line as the movie_id\n",
    "        movie_id = lines[0].split(':')[0]\n",
    "\n",
    "        # Process the remaining lines\n",
    "        for line in lines[1:]:\n",
    "            user_id = line.split(',')[0]\n",
    "            user_ratings[user_id] = user_ratings.get(user_id, 0) + 1\n",
    "\n",
    "        return movie_id\n",
    "\n",
    "# Loop through the top 1000 longest files\n",
    "i = 0\n",
    "for file in top_1000_longest_files:\n",
    "    file_path = os.path.join(directory, file[0])\n",
    "    movie_mapping[count_user_ratings(file_path)] = i\n",
    "    i += 1\n",
    "\n",
    "# Find the top 1000 users with the most ratings\n",
    "top_1000_users = sorted(user_ratings.items(), key=lambda x: x[1], reverse=True)[:1000]\n",
    "\n",
    "# Assign a unique index to each user\n",
    "i = 0\n",
    "for user in top_1000_users:\n",
    "    user_mapping[user[0]] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# Loop through the top 1000 longest files\n",
    "for file in top_1000_longest_files:\n",
    "    file_path = os.path.join(directory, file[0])\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "        # Get the movie index\n",
    "        movie_index = movie_mapping[lines[0].split(':')[0]]\n",
    "\n",
    "        # Process the remaining lines\n",
    "        for line in lines[1:]:\n",
    "            user_id, rating, _ = line.split(',')\n",
    "            \n",
    "            # Get the user index\n",
    "            user_index = user_mapping.get(user_id, -1)\n",
    "            \n",
    "            # Append the movie index, user index, and rating to the dataset\n",
    "            if user_index != -1:\n",
    "                dataset.append((movie_index, user_index, int(rating)))\n",
    "\n",
    "# Create a pandas DataFrame from the dataset\n",
    "df = pd.DataFrame(dataset, columns=['Movie Index', 'User Index', 'Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data density\n",
    "num_users = len(user_mapping)\n",
    "num_movies = len(movie_mapping)\n",
    "num_ratings = len(df)\n",
    "\n",
    "density = num_ratings / (num_users * num_movies)\n",
    "\n",
    "print(f'Number of users: {num_users}')\n",
    "print(f'Number of movies: {num_movies}')\n",
    "print(f'Number of ratings: {num_ratings}')\n",
    "print(f'Density: {density:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to a CSV file\n",
    "df.to_csv('Small/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV dataset file\n",
    "df = pd.read_csv('Small/dataset.csv')\n",
    "\n",
    "# Remap user ids\n",
    "df['User Index'] = df['User Index'].rank(method='dense') - 1\n",
    "\n",
    "# Remap movie ids\n",
    "df['Movie Index'] = df['Movie Index'].rank(method='dense') - 1\n",
    "\n",
    "# Convert the columns to integers\n",
    "df['User Index'] = df['User Index'].astype(int)\n",
    "df['Movie Index'] = df['Movie Index'].astype(int)\n",
    "\n",
    "# Write the updated dataset to the CSV file\n",
    "df.to_csv('Small/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID range: 0 - 999\n",
      "User ID range: 0 - 999\n",
      "Unique Movie IDs: 1000\n",
      "Unique User IDs: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV dataset file\n",
    "df = pd.read_csv('Small/dataset.csv')\n",
    "\n",
    "# Get the range of movie IDs and user IDs\n",
    "min_movie_id = df['Movie Index'].min()\n",
    "max_movie_id = df['Movie Index'].max()\n",
    "min_user_id = df['User Index'].min()\n",
    "max_user_id = df['User Index'].max()\n",
    "\n",
    "# Get the total number of unique movie IDs and user IDs\n",
    "unique_movie_ids = df['Movie Index'].nunique()\n",
    "unique_user_ids = df['User Index'].nunique()\n",
    "\n",
    "# Verify the range of movie IDs and user IDs\n",
    "print(\"Movie ID range:\", min_movie_id, \"-\", max_movie_id)\n",
    "print(\"User ID range:\", min_user_id, \"-\", max_user_id)\n",
    "print(\"Unique Movie IDs:\", unique_movie_ids)\n",
    "print(\"Unique User IDs:\", unique_user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "directory = 'Raw/training_set'\n",
    "\n",
    "# Create the output file or clear the existing file\n",
    "output_filepath = 'Full/dataset.csv'\n",
    "with open(output_filepath, 'w') as output_file:\n",
    "    output_file.write('Movie Index,User Index,Rating\\n')\n",
    "\n",
    "# Get the total number of files\n",
    "total_files = len(os.listdir(directory))\n",
    "\n",
    "# Loop through each file in the directory with a progress bar\n",
    "for filename in tqdm(os.listdir(directory), total=total_files, desc='Processing files'):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    # Read the file\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Save the first line as the movie_id\n",
    "        movie_id = lines[0].split(':')[0]\n",
    "\n",
    "        # Save the remaining lines as the user - rating pairs\n",
    "        user_ratings = lines[1:]\n",
    "\n",
    "        # Save the user - rating pairs to the output file\n",
    "        with open(output_filepath, 'a') as output_file:\n",
    "            for user_rating in user_ratings:\n",
    "                # Split user and rating\n",
    "                user_id, rating, _ = user_rating.split(',')\n",
    "\n",
    "                # Write the movie index, user index, and rating to the output file\n",
    "                output_file.write(f'{movie_id},{user_id},{rating}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV dataset file\n",
    "df = pd.read_csv('Full/dataset.csv')\n",
    "\n",
    "# Remap user ids\n",
    "df['User Index'] = df['User Index'].rank(method='dense') - 1\n",
    "\n",
    "# Remap movie ids\n",
    "df['Movie Index'] = df['Movie Index'].rank(method='dense') - 1\n",
    "\n",
    "# Convert the columns to integers\n",
    "df['User Index'] = df['User Index'].astype(int)\n",
    "df['Movie Index'] = df['Movie Index'].astype(int)\n",
    "\n",
    "# Write the updated dataset to the CSV file\n",
    "df.to_csv('Full/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID range: 0 - 17769\n",
      "User ID range: 0 - 480188\n",
      "Unique Movie IDs: 17770\n",
      "Unique User IDs: 480189\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV dataset file\n",
    "df = pd.read_csv('Full/dataset.csv')\n",
    "\n",
    "# Get the range of movie IDs and user IDs\n",
    "min_movie_id = df['Movie Index'].min()\n",
    "max_movie_id = df['Movie Index'].max()\n",
    "min_user_id = df['User Index'].min()\n",
    "max_user_id = df['User Index'].max()\n",
    "\n",
    "# Get the total number of unique movie IDs and user IDs\n",
    "unique_movie_ids = df['Movie Index'].nunique()\n",
    "unique_user_ids = df['User Index'].nunique()\n",
    "\n",
    "# Verify the range of movie IDs and user IDs\n",
    "print(\"Movie ID range:\", min_movie_id, \"-\", max_movie_id)\n",
    "print(\"User ID range:\", min_user_id, \"-\", max_user_id)\n",
    "print(\"Unique Movie IDs:\", unique_movie_ids)\n",
    "print(\"Unique User IDs:\", unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the dataset from the CSV file\n",
    "# df = pd.read_csv('Full/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get some statistics about the data\n",
    "# import json\n",
    "\n",
    "# # Number of unique users\n",
    "# num_users = df['User Index'].nunique()\n",
    "\n",
    "# # Number of unique movies\n",
    "# num_movies = df['Movie Index'].nunique()\n",
    "\n",
    "# # Mean rating\n",
    "# mean_rating = df['Rating'].astype(int).mean()\n",
    "\n",
    "# # Density\n",
    "# density = len(df) / (num_users * num_movies)\n",
    "\n",
    "# # Save these statistic to a JSON file\n",
    "# stats = {\n",
    "#     'num_users': num_users,\n",
    "#     'num_movies': num_movies,\n",
    "#     'mean_rating': mean_rating,\n",
    "#     'density': density\n",
    "# }\n",
    "\n",
    "# with open('Full/stats.json', 'w') as file:\n",
    "#     json.dump(stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the dataset into train and test data\n",
    "# train_data, test_data = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Print the shapes of train and test data\n",
    "# print(\"Train data shape:\", train_data.shape)\n",
    "# print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# # Sort the DataFrame by User Index\n",
    "# train_data = train_data.groupby('User Index')\n",
    "\n",
    "# # Save each user's ratings to a separate CSV file\n",
    "# for user_index, user_data in tqdm(train_data, desc='Saving user ratings', total=num_users):\n",
    "#     user_data.to_csv(f'Full/Train/{user_index}.csv', index=False)\n",
    "\n",
    "# # Sort the DataFrame by User Index\n",
    "# test_data = test_data.groupby('User Index')\n",
    "\n",
    "# # Save each user's ratings to a separate CSV file\n",
    "# for user_index, user_data in tqdm(test_data, desc='Saving user ratings', total=num_users):\n",
    "#     user_data.to_csv(f'Full/Test/{user_index}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete all the files in the generated data directory\n",
    "# import shutil\n",
    "\n",
    "# shutil.rmtree('Full/Train')\n",
    "# shutil.rmtree('Full/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
