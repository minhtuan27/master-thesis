{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(raw_file, output_file):\n",
    "    with open(raw_file, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the column names to the CSV file\n",
    "        writer.writerow(['Movie Index', 'User Index', 'Rating'])\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        for line in data:\n",
    "            line = line.strip().split()\n",
    "            user_index = line[0]\n",
    "            for movie_index in line[1:]:\n",
    "                writer.writerow([movie_index, user_index, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process amazon-book data\n",
    "process_data('amazon-book/train.txt', 'amazon-book/train.csv')\n",
    "process_data('amazon-book/test.txt', 'amazon-book/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process gowalla data\n",
    "process_data('gowalla/train.txt', 'gowalla/train.csv')\n",
    "process_data('gowalla/test.txt', 'gowalla/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process yelp2018 data\n",
    "process_data('yelp2018/train.txt', 'yelp2018/train.csv')\n",
    "process_data('yelp2018/test.txt', 'yelp2018/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon-book dataset\n",
      "Train data dimensions: 91599 52643\n",
      "Train data index ranges: 0 91598 0 52642\n",
      "Test data dimensions: 82629 52639\n",
      "Test data index ranges: 0 91598 0 52642\n"
     ]
    }
   ],
   "source": [
    "# Confirm the dimensions of each dataset\n",
    "train_data = pd.read_csv('amazon-book/train.csv')\n",
    "test_data = pd.read_csv('amazon-book/test.csv')\n",
    "print('Amazon-book dataset')\n",
    "print('Train data dimensions:', train_data['Movie Index'].nunique(), train_data['User Index'].nunique())\n",
    "print('Train data index ranges:', train_data['Movie Index'].min(), train_data['Movie Index'].max(), train_data['User Index'].min(), train_data['User Index'].max())\n",
    "print('Test data dimensions:', test_data['Movie Index'].nunique(), test_data['User Index'].nunique())\n",
    "print('Test data index ranges:', test_data['Movie Index'].min(), test_data['Movie Index'].max(), test_data['User Index'].min(), test_data['User Index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gowalla dataset\n",
      "Train data dimensions: 40981 29858\n",
      "Train data index ranges: 0 40980 0 29857\n",
      "Test data dimensions: 38546 29858\n",
      "Test data index ranges: 0 40980 0 29857\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('gowalla/train.csv')\n",
    "test_data = pd.read_csv('gowalla/test.csv')\n",
    "print('Gowalla dataset')\n",
    "print('Train data dimensions:', train_data['Movie Index'].nunique(), train_data['User Index'].nunique())\n",
    "print('Train data index ranges:', train_data['Movie Index'].min(), train_data['Movie Index'].max(), train_data['User Index'].min(), train_data['User Index'].max())\n",
    "print('Test data dimensions:', test_data['Movie Index'].nunique(), test_data['User Index'].nunique())\n",
    "print('Test data index ranges:', test_data['Movie Index'].min(), test_data['Movie Index'].max(), test_data['User Index'].min(), test_data['User Index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp2018 dataset\n",
      "Train data dimensions: 38048 31668\n",
      "Train data index ranges: 0 38047 0 31667\n",
      "Test data dimensions: 36073 31668\n",
      "Test data index ranges: 0 38047 0 31667\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('yelp2018/train.csv')\n",
    "test_data = pd.read_csv('yelp2018/test.csv')\n",
    "print('Yelp2018 dataset')\n",
    "print('Train data dimensions:', train_data['Movie Index'].nunique(), train_data['User Index'].nunique())\n",
    "print('Train data index ranges:', train_data['Movie Index'].min(), train_data['Movie Index'].max(), train_data['User Index'].min(), train_data['User Index'].max())\n",
    "print('Test data dimensions:', test_data['Movie Index'].nunique(), test_data['User Index'].nunique())\n",
    "print('Test data index ranges:', test_data['Movie Index'].min(), test_data['Movie Index'].max(), test_data['User Index'].min(), test_data['User Index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Sample a 1000 by 4 matrix from the normal distribution\n",
    "matrix_1000_4 = np.random.normal(size=(1000, 4))\n",
    "\n",
    "# Sample a 4 by 1000 matrix from the normal distribution\n",
    "matrix_4_1000 = np.random.normal(size=(4, 1000))\n",
    "\n",
    "# Compute the product of the two matrices\n",
    "product = np.dot(matrix_1000_4, matrix_4_1000)\n",
    "\n",
    "# Compute the sigmoid function of the product\n",
    "sigmoid = 1 / (1 + np.exp(-product))\n",
    "\n",
    "# Get all position where the sigmoid is greater than 0.5\n",
    "indices = np.where(sigmoid > 0.5)\n",
    "\n",
    "# Save 80% of the indices to a train csv file and 20% to a test csv file\n",
    "indices = list(zip(*indices))\n",
    "np.random.shuffle(indices)\n",
    "split = int(0.8 * len(indices))\n",
    "train_indices = indices[:split]\n",
    "\n",
    "with open('toy-dataset/train.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Movie Index', 'User Index', 'Rating'])\n",
    "    for row, col in train_indices:\n",
    "        writer.writerow([row, col, 1])\n",
    "\n",
    "test_indices = indices[split:]\n",
    "\n",
    "with open('toy-dataset/test.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Movie Index', 'User Index', 'Rating'])\n",
    "    for row, col in test_indices:\n",
    "        writer.writerow([row, col, 1])\n",
    "\n",
    "# Wrte the true original matrices to csv files\n",
    "np.savetxt('toy-dataset/C.csv', matrix_1000_4, delimiter=',')\n",
    "np.savetxt('toy-dataset/X.csv', matrix_4_1000, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
