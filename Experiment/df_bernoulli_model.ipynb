{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation\n",
    "\n",
    "$$\n",
    "x_k := \\text{argmax } p(y_k | c, x_k)p(x_k) = \\text{argmax} \\left( log\\ p(y_k | c, x_k) + log\\ p(x_k) \\right)\n",
    "$$\n",
    "\n",
    "where $p(y_k | c, x_k) = Bernoulli(y_k; \\psi(cx_k))$ and $p(x_k) = N(0, \\sigma_x^2)$. $\\psi$ is the sigmoid function.\n",
    "\n",
    "Then, we obtain the gradient descent update for $x_k$:\n",
    "$$\n",
    "x_k := x_k + \\gamma_x (c^\\intercal (y_k (1 - \\psi(cx_k)) - (1 - y_k)\\psi(cx_k)) - x_k / \\sigma_x^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the update for $c$ is:\n",
    "\n",
    "$$\n",
    "c := c + \\gamma_c \\nabla log \\pi(c) = c + \\gamma_c ((y_k(1 - \\psi(cx_k)) - (1-y_k)\\psi(cx_k)) x_k^\\intercal - c / \\sigma_c^2)\n",
    "$$\n",
    "\n",
    "Incorporating Langevin Monte Carlo (LMC),\n",
    "\n",
    "$$\n",
    "\\tilde{c} := c + \\gamma_c ((y_k(1 - \\psi(cx_k)) - (1-y_k)\\psi(cx_k)) x_k^\\intercal - c / \\sigma_c^2) + \\sqrt{2 \\gamma_c} \\xi\n",
    "$$\n",
    "\n",
    "According to the Metropolis-Hastings algorithm,\n",
    "$$\n",
    "\\alpha := min\\left(1, \\frac{\\pi(\\tilde{c})q(c | \\tilde{c})}{\\pi(c)q(\\tilde{c}|c)} \\right)\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "log q(\\tilde{c}|c) = -\\frac{1}{4\\gamma_c} ||\\tilde{c} - c - \\gamma_c \\nabla log \\pi(c)||_2^2\n",
    "$$\n",
    "\n",
    "and\n",
    "$$\n",
    "log \\pi(c) = ||y_k log(\\psi(cx_k)) + (1-y_k) log(1-\\psi(cx_k))||_1^1 - \\frac{1}{2\\sigma_c^2}||c||_2^2 + const\n",
    "$$\n",
    "$$\n",
    "= ||y_k log\\psi(cx_k) + (1-y_k) log\\psi(-cx_k)||_1^1 - \\frac{1}{2\\sigma_c^2}||c||_2^2 + const\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([[1, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 1]])\n",
    "C = np.random.normal(0, 1, (4, 2))\n",
    "X = np.random.normal(0, 1, (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.96400435e-01 9.89031032e-01 1.01593689e-02 1.13005846e-02]\n",
      " [9.95458948e-01 8.02939503e-03 9.92470554e-01 5.38374871e-04]\n",
      " [1.06460108e-02 9.89964205e-01 9.43137002e-03 9.98529026e-01]\n",
      " [3.51451942e-03 1.07518647e-02 9.90045282e-01 9.88906728e-01]]\n",
      "[[-2.53636577  0.31088616]\n",
      " [-0.06940218  3.04309861]\n",
      " [-0.08177743 -2.72146677]\n",
      " [ 2.54744778 -0.31191174]]\n",
      "[[-2.00558751 -1.97436881  2.00762392  1.46390897]\n",
      " [ 1.72549553 -1.6278177   1.64986746 -2.43988756]]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.01\n",
    "sigma = 10.0\n",
    "for i in range(1000):\n",
    "    X = X + gamma * (C.T @ (Y * (1 - sigmoid(C @ X)) - (1 - Y) * sigmoid(C @ X)) - (X / (sigma ** 2)))\n",
    "    C = C + gamma * ((Y * (1 - sigmoid(C @ X)) - (1 - Y) * sigmoid(C @ X)) @ X.T - (C / (sigma ** 2)))\n",
    "print(sigmoid(C @ X))\n",
    "print(C)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 15:48:00.664307: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-14 15:48:00.685014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-14 15:48:00.685025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-14 15:48:00.685767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-14 15:48:00.689547: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-14 15:48:01.058689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../Library')\n",
    "\n",
    "from Modules.BernoulliDF import BernoulliDF as DictionaryFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 15:48:01.675804: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.690402: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.690435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.692111: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.692145: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.692168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.790498: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.790543: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.790550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-08-14 15:48:01.790582: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-14 15:48:01.790596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-08-14 15:48:02.272496: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.53824833 -3.87854329]\n",
      " [ 8.21365793 10.17792422]\n",
      " [ 0.10772691 -3.76852549]\n",
      " [ 0.67708596 -0.98721746]]\n",
      "[[-2.53147254 -3.92020529  3.92020529  2.53147254]\n",
      " [ 2.72162107 -0.69270141  0.69270141 -2.72162107]]\n",
      "[[9.99801980e-01 1.00000000e+00 9.98039850e-15 1.98020192e-04]\n",
      " [9.99001047e-01 8.99837495e-18 1.00000000e+00 9.98952850e-04]\n",
      " [2.67431324e-05 8.99180436e-01 1.00819564e-01 9.99973257e-01]\n",
      " [1.21181789e-02 1.22338517e-01 8.77661483e-01 9.87881821e-01]]\n"
     ]
    }
   ],
   "source": [
    "model = DictionaryFilter(4, 4, 2, 0.1, 10.0, 0.1, 10.0)\n",
    "\n",
    "Y = tf.constant([[1, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 1]], dtype=tf.float64)\n",
    "k = tf.constant(0)\n",
    "for i in range(1000):\n",
    "    Y_hat = model(Y, k)\n",
    "\n",
    "print(model.C.numpy())\n",
    "print(model.X.numpy())\n",
    "print(Y_hat.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the gowalla dataset\n",
    "train_data = pd.read_csv('../Data/Binary/toy-dataset/train.csv')\n",
    "test_data = pd.read_csv('../Data/Binary/toy-dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399920, 3)\n",
      "(99980, 3)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the data\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MOVIES = train_data['Movie Index'].max() + 1\n",
    "NUM_USERS = train_data['User Index'].max() + 1\n",
    "NUM_FACTORS = 4\n",
    "BATCH_SIZE = 250\n",
    "GAMMA_C = 0.0001\n",
    "GAMMA_X = 0.0001\n",
    "SIGMA_C = 1.0\n",
    "SIGMA_X = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train data to sparse tensor\n",
    "train_sparse_tensor = tf.sparse.SparseTensor(\n",
    "    indices=train_data[['Movie Index', 'User Index']].values,\n",
    "    values=train_data['Rating'].values,\n",
    "    dense_shape=[NUM_MOVIES, NUM_USERS]\n",
    ")\n",
    "train_sparse_tensor = tf.sparse.reorder(train_sparse_tensor)\n",
    "\n",
    "# Convert test data to sparse tensor\n",
    "test_sparse_tensor = tf.sparse.SparseTensor(\n",
    "    indices=test_data[['Movie Index', 'User Index']].values,\n",
    "    values=test_data['Rating'].values,\n",
    "    dense_shape=[NUM_MOVIES, NUM_USERS]\n",
    ")\n",
    "test_sparse_tensor = tf.sparse.reorder(test_sparse_tensor)\n",
    "\n",
    "# Create dataset\n",
    "def data_generator():\n",
    "    train_slices = tf.sparse.split(sp_input=train_sparse_tensor, num_split=NUM_USERS // BATCH_SIZE, axis=1)\n",
    "    test_slices = tf.sparse.split(sp_input=test_sparse_tensor, num_split=NUM_USERS // BATCH_SIZE, axis=1)\n",
    "    for i in range(NUM_USERS // BATCH_SIZE):\n",
    "        yield (tf.sparse.to_dense(train_slices[i]), tf.sparse.to_dense(test_slices[i]))\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=[NUM_MOVIES, None], dtype=tf.float64),\n",
    "        tf.TensorSpec(shape=[NUM_MOVIES, None], dtype=tf.float64)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [00:09<00:00, 10.00it/s, Recall=0.0333, NDCG=0.701]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Create the model\n",
    "model = DictionaryFilter(NUM_MOVIES, NUM_USERS, NUM_FACTORS, GAMMA_X, SIGMA_X, GAMMA_C, SIGMA_C)\n",
    "recall = tf.keras.metrics.Recall(top_k=20)\n",
    "ndcg = tfr.keras.metrics.NDCGMetric(topn=20)\n",
    "# min_recall = tf.keras.metrics.Recall(top_k=20) ~ 0.02 on toy-dataset\n",
    "# min_ndcg = tfr.keras.metrics.NDCGMetric(topn=20) ~ 0.5 on toy-dataset\n",
    "# max_recall = tf.keras.metrics.Recall(top_k=20) ~ 0.2 on toy-dataset\n",
    "# max_ndcg = tfr.keras.metrics.NDCGMetric(topn=20) ~ 1.0 on toy-dataset\n",
    "\n",
    "# Train the model\n",
    "progress_bar = tqdm(range(100), desc=\"Training Progress\", total=100)\n",
    "for epoch in progress_bar:\n",
    "    k = tf.Variable(0, trainable=False)\n",
    "    for train_batch, test_batch in dataset:\n",
    "        Y_hat = model(train_batch, k)\n",
    "        k.assign_add(train_batch.shape[1])\n",
    "\n",
    "        # Compute the metrics\n",
    "        Y_test = tf.multiply(Y_hat, tf.subtract(1.0, train_batch))\n",
    "        recall.update_state(tf.transpose(Y_test), tf.transpose(test_batch))\n",
    "        ndcg.update_state(tf.transpose(Y_test), tf.transpose(test_batch))\n",
    "\n",
    "    # Update the progress bar description\n",
    "    progress_bar.set_postfix({\"Recall\": recall.result().numpy(), \"NDCG\": ndcg.result().numpy()})\n",
    "\n",
    "    recall.reset_states()\n",
    "    ndcg.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
